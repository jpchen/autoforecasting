{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwNlnuBk9J0D"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "mplementing kernels designed in Automatic forecasting using Gaussian Process [1] and test results with the M4 dataset. For now, only small sections of the M4 training and testing datasets are being used.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gY7evOzC9J0I"
      },
      "source": [
        "# Data loading and visualization\n",
        "The data is available at the following path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "PymKLSVD9J0I",
        "outputId": "e2628db8-a4b9-49b7-9e06-197318fa10c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gpytorch\n",
            "  Downloading gpytorch-1.11-py3-none-any.whl (266 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.1/266.1 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from gpytorch) (1.2.2)\n",
            "Collecting linear-operator>=0.5.0 (from gpytorch)\n",
            "  Downloading linear_operator-0.5.0-py3-none-any.whl (172 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.0/173.0 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.11 in /usr/local/lib/python3.10/dist-packages (from linear-operator>=0.5.0->gpytorch) (2.0.1+cu118)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from linear-operator>=0.5.0->gpytorch) (1.10.1)\n",
            "Collecting jaxtyping>=0.2.9 (from linear-operator>=0.5.0->gpytorch)\n",
            "  Downloading jaxtyping-0.2.20-py3-none-any.whl (24 kB)\n",
            "Collecting typeguard~=2.13.3 (from linear-operator>=0.5.0->gpytorch)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->gpytorch) (1.22.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->gpytorch) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->gpytorch) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.10/dist-packages (from jaxtyping>=0.2.9->linear-operator>=0.5.0->gpytorch) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->linear-operator>=0.5.0->gpytorch) (3.12.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->linear-operator>=0.5.0->gpytorch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->linear-operator>=0.5.0->gpytorch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->linear-operator>=0.5.0->gpytorch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->linear-operator>=0.5.0->gpytorch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11->linear-operator>=0.5.0->gpytorch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11->linear-operator>=0.5.0->gpytorch) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11->linear-operator>=0.5.0->gpytorch) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11->linear-operator>=0.5.0->gpytorch) (1.3.0)\n",
            "Installing collected packages: typeguard, jaxtyping, linear-operator, gpytorch\n",
            "Successfully installed gpytorch-1.11 jaxtyping-0.2.20 linear-operator-0.5.0 typeguard-2.13.3\n"
          ]
        }
      ],
      "source": [
        "from pandas.core.groupby.generic import DataFrameGroupBy\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import torch\n",
        "!pip install gpytorch # This is to allow gpytorch to work on any Google Colab Notebook\n",
        "import gpytorch as gp\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8SH4B_0SxNI"
      },
      "source": [
        "Setting up the full m4 dataset and any subsets (ex. monthly, weekly, hourly, etc.) that might be analyzed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QKL9oDvLSt93",
        "outputId": "004a75b2-58d6-4a88-b824-96ead6942058"
      },
      "outputs": [
        {
          "ename": "ParserError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-4175acd86520>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/M4-info.csv'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# This is for the m4 dataset as a whole\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/Monthly-test.csv\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Monthly dataset for testing purposes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/Monthly-train.csv\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Monthly dataset for training purposes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1776\u001b[0m                     \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m                     \u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1778\u001b[0;31m                 \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1779\u001b[0m                     \u001b[0mnrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1780\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: EOF inside string starting at row 11554"
          ]
        }
      ],
      "source": [
        "random.seed(0)\n",
        "df = pd.read_csv('/content/M4-info.csv') # This is for the m4 dataset as a whole\n",
        "df_test = pd.read_csv(\"/content/Monthly-test.csv\") # Monthly dataset for testing purposes\n",
        "df_train = pd.read_csv(\"/content/Monthly-train.csv\") # Monthly dataset for training purposes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2sqZmdsbdgah"
      },
      "outputs": [],
      "source": [
        "df # Just to review the M4_Info dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QUvWR7TDe87H"
      },
      "outputs": [],
      "source": [
        "df_train # Good too see how the training set compares to the info set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "52gPvBp98W01"
      },
      "outputs": [],
      "source": [
        "df_test # Good too see how the testing set compares to the info set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAPIpnsb9J0K"
      },
      "source": [
        "Select series_id for one product, and we'll fit GP as a univariate model. Code not used for now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6NTl5u9M9J0L"
      },
      "outputs": [],
      "source": [
        "''' Code Not Used as datasets are set up separately. Might used later if applicable\n",
        "series_id = 'M2573'\n",
        "num_test = 18\n",
        "df = df[df['M4id']==series_id] # M4id corresponds to the series_id in the original m3 dataset.\n",
        "df\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCQjvFrk9J0L"
      },
      "source": [
        "## Setting a new dataset with one row from the training dataset\n",
        "We visualize the data of one row in the M4 dataset and put that rows into its own dataset, which will now be used for the training dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IuEzkAGQhNjo"
      },
      "outputs": [],
      "source": [
        "df_2 = df_train.loc[2574].to_frame() # This is a dataframe housing the row that I chose, which I believe is the one with the most elements.\n",
        "df_2 = df_2.dropna()\n",
        "df_2 = pd.DataFrame(df_2) # Just confirming that we made a new dataframe\n",
        "df_2[\"index\"] = df_2.index # There are the indexes corresponding to each element\n",
        "items = df_2.iloc[:, 0]\n",
        "df_2 = df_2.assign(items=items)\n",
        "df_2 = df_2.drop(\"V1\")\n",
        "df_2['index'] = df_2['index'].str.replace('V', '') # Removing V from each index so that indecies are numbers\n",
        "df_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bAkOUAux9J0L"
      },
      "outputs": [],
      "source": [
        "plt.rcParams['figure.figsize'] = 12, 8\n",
        "sns.lineplot(x='index', y='items', data=df_2) # Revised based on how I formatted the dataset.\n",
        "plt.xlabel('Month - Index of Each Element')\n",
        "plt.ylabel('Value')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3l0ZvJe79J0M"
      },
      "source": [
        "## Plotting the auto-correlation\n",
        "We plot the auto correlcation function below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mhUSPCbE9J0M"
      },
      "outputs": [],
      "source": [
        "from statsmodels.graphics.tsaplots import plot_acf\n",
        "acf = plot_acf(df_2['items'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gc7mQOmJ801C"
      },
      "source": [
        "## Setting a new dataset with one row from the testing dataset\n",
        "We visualize the data of one row in the M4 dataset and put that rows into its own dataset, which will now be used for the testing dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "e5kPX5ZC84Vt"
      },
      "outputs": [],
      "source": [
        "df_3 = df_test.loc[2574].to_frame() # This is a dataframe housing the row that I chose.\n",
        "df_3 = df_3.dropna()\n",
        "df_3 = pd.DataFrame(df_3) # Just confirming that we made a new dataframe\n",
        "df_3[\"index\"] = df_3.index # There are the indexes corresponding to each element\n",
        "items = df_3.iloc[:, 0]\n",
        "df_3 = df_3.assign(items=items)\n",
        "df_3 = df_3.drop(\"V1\")\n",
        "df_3['index'] = df_3['index'].str.replace('V', '') # Removing V from each index so that indecies are numbers\n",
        "j = 1855\n",
        "for i in range(len(df_3['index'])): # This makes the indecies of the testing dataset to be after the training set's indecies.\n",
        "  df_3['index'][i] = j\n",
        "  j = j + 1\n",
        "df_3 # Change the indecies of the testing dataset for its first index to be after than the last index of training dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "u5HgxQj39WZL"
      },
      "outputs": [],
      "source": [
        "# This is for the testing dataset\n",
        "plt.rcParams['figure.figsize'] = 12, 8\n",
        "sns.lineplot(x='index', y='items', data=df_3) # Revised based on how I formatted the dataset.\n",
        "plt.xlabel('Month - Index of Each Element')\n",
        "plt.ylabel('Value')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAzSu1MTbgKd"
      },
      "source": [
        "## **Data Testing - Basic**\n",
        "We prepare the training set and test set data and work with using basic GPs. The data needs to be converted to tensors to work, so some precision of the data is lost. The data is converted to int32 tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WFXHTPbHbfXE"
      },
      "outputs": [],
      "source": [
        "# From the newly created training dataset df_2\n",
        "x_train = df_2[\"index\"] # Months\n",
        "x_train = torch.from_numpy(x_train.values.astype(np.float32))\n",
        "\n",
        "y_train = df_2[\"items\"] # Values\n",
        "y_train = torch.from_numpy(y_train.values.astype(np.float32))\n",
        "\n",
        "# From the newly created testing dataset df_3\n",
        "x_test = df_3[\"index\"] # Months\n",
        "x_test = torch.from_numpy(x_test.values.astype(np.float32))\n",
        "\n",
        "y_test = df_3[\"items\"] # Values\n",
        "y_test = torch.from_numpy(y_test.values.astype(np.float32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "y9p7NTkUG7-D"
      },
      "outputs": [],
      "source": [
        "# Using the tutorial code for the simplified testing and training with the dataset.\n",
        "# Will need to change the GPModel being used as needed.\n",
        "\n",
        "# Fit the right side of the data at the change in the training graph. See sharp turn.\n",
        "class GPModel(gp.models.ExactGP):\n",
        "  def __init__(self, train_x, train_y, likelihood):\n",
        "        super(GPModel, self).__init__(train_x, train_y, likelihood)\n",
        "        self.mean_module = gp.means.ConstantMean()\n",
        "        self.covar_module = gp.kernels.ScaleKernel(gp.kernels.RBFKernel() * gp.kernels.PeriodicKernel() + gp.kernels.RQKernel()) # Most effective of the combinations I tried, but by the 100th test, the negative LL is still 3023.869.\n",
        "        # elf.covar_module = gp.kernels.ScaleKernel(gp.kernels.RBFKernel() * gp.kernels.PeriodicKernel() + gp.kernels.LinearKernel() * gp.kernels.PeriodicKernel()) - This gives low initial losses, but they increase once we go past the 50th round.\n",
        "        # self.covar_module.initialize_from_data(x_train.type(torch.float32), y_train.type(torch.float32)) # Only for the SpectralMixture Kernel\n",
        "  def forward(self, x):\n",
        "    mean_x = self.mean_module(x)\n",
        "    covar_x = self.covar_module(x)\n",
        "    return gp.distributions.MultivariateNormal(mean_x, covar_x)\n",
        "  def mse(y_true, y_pred):\n",
        "    # Mean squared error function.\n",
        "    y_pred_tensor = y_pred.sample()\n",
        "    return ((y_true - y_pred_tensor)**2).mean()\n",
        "\n",
        "  def mae(y_true, y_pred):\n",
        "    # Mean absolute error function.\n",
        "    y_pred_tensor = y_pred.sample()\n",
        "    return torch.abs((y_true - y_pred_tensor)**2).mean()\n",
        "\n",
        "  def crps(y_true, y_pred):\n",
        "    # Continuous ranked probability score function.\n",
        "    y_pred_tensor = y_pred.sample()\n",
        "    return torch.mean(torch.distributions.Normal(y_pred_tensor, torch.sqrt(y_pred_tensor.std())).cdf(y_true))\n",
        "\n",
        "likelihood = gp.likelihoods.GaussianLikelihood()\n",
        "model = GPModel(x_train, y_train, likelihood)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qXTCZwtOHPAM"
      },
      "outputs": [],
      "source": [
        "# This takes between 1-16 minutes on my laptop, for reference\n",
        "\n",
        "# Running the notebook in the tutorial's testing framework\n",
        "import os\n",
        "smoke_test = (\"CI\" in os.environ)\n",
        "training_iter = 2 if smoke_test else 40100 # else __ of training iterations\n",
        "# 40189 was maximum before runtime failed. Reached a low of 39.363\n",
        "# This took my computer around 4-6 hours.\n",
        "\n",
        "# Finding the optimal parameters for the model\n",
        "model.train()\n",
        "likelihood.train()\n",
        "\n",
        "# Using the ADAM optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.1) # Change the learning rate as needed. Lower should be better.\n",
        "\n",
        "# Finding the marginal log likelihood, or the \"loss\" for GPs\n",
        "mll = gp.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
        "\n",
        "for i in range(training_iter):\n",
        "  optimizer.zero_grad()\n",
        "  output = model(x_train)\n",
        "  loss = -mll(output, y_train)\n",
        "  loss.backward()\n",
        "  print(\"Iter %d/%d - Loss: %.3f\" % (i + 1, training_iter, loss.item()))\n",
        "  optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dYor6ZjtHiJZ"
      },
      "outputs": [],
      "source": [
        "# Get into evaluation mode, or the predictive posterior mode\n",
        "# Add the training and test metrics. Ex. MSE and MAE and CRPS. Test each individually.\n",
        "# These tests have been incorporated as functions into the GPModel Class\n",
        "\n",
        "model.eval()\n",
        "likelihood.eval()\n",
        "\n",
        "with torch.no_grad(), gp.settings.fast_pred_var():\n",
        "    # Making predictions\n",
        "    observed_pred = likelihood(model(x_test))\n",
        "\n",
        "    # Initializing the plot\n",
        "    f, ax = plt.subplots(1, 1, figsize=(4, 3))\n",
        "\n",
        "    # Getting the upper and lower confidence bounds\n",
        "    lower, upper = observed_pred.confidence_region()\n",
        "    # Plotting training data as black stars\n",
        "    ax.plot(x_train.numpy(), y_train.numpy(), 'k*')\n",
        "    # Plotting predictive means as blue line\n",
        "    ax.plot(x_test.numpy(), observed_pred.mean.numpy(), 'b')\n",
        "    # Shading the region between the lower and upper confidence bounds\n",
        "    ax.fill_between(x_test.numpy(), lower.numpy(), upper.numpy(), alpha=0.5)\n",
        "    # ax.set_ylim([0, 2000])\n",
        "    ax.set_xlim([1400, 2000])\n",
        "    # plt.fit()\n",
        "    ax.legend(['Observed Data', 'Mean', 'Confidence'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eSNW7fLcd1F"
      },
      "source": [
        "# Evaluation for Basic Testing\n",
        "We measure mean absolute error (MAE), continuous-ranked probability score (CRPS), and log-likelihood (LL) using normalized values on both of the training set and the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ppwulM3AeJzF"
      },
      "outputs": [],
      "source": [
        "y_pred = model(x_train)\n",
        "mse_train = GPModel.mse(y_train, y_pred)\n",
        "mae_train = GPModel.mae(y_train, y_pred)\n",
        "crps_train = GPModel.crps(y_train, y_pred)\n",
        "\n",
        "print(\"MSE train:\", mse_train)\n",
        "print(\"MAE train:\", mae_train)\n",
        "print(\"CRPS train:\", crps_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ObNeoLvi9rb0"
      },
      "outputs": [],
      "source": [
        "# Importing and installing sts so it can be used later on. This does not work. I need to fix this.\n",
        "!pip install git+https://github.com/jpchen/autoforecasting.git\n",
        "from sts.data import get_mvn_stats\n",
        "from torch.distributions import ComposeTransform, ExpTransform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mdCU6kIpcd1G"
      },
      "outputs": [],
      "source": [
        "train_mean, train_var, train_ci = get_mvn_stats(model.predict(x_train))\n",
        "test_mean, test_var, test_ci = get_mvn_stats(model.predict(x_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pt9ih0ejcd1G"
      },
      "source": [
        "Here we compute MAE for both training data and test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4htj4b-Ycd1G"
      },
      "outputs": [],
      "source": [
        "from sts.metrics import MAE\n",
        "MAE_train = MAE(y_train.tensor, train_mean).item()\n",
        "MAE_test = MAE(y_test.tensor, test_mean).item()\n",
        "print(f'Mean absolute error for training set is: {MAE_train:.3f}')\n",
        "print(f'Mean absolute error for test set is: {MAE_test:.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HvQXjTOcd1G"
      },
      "source": [
        "Here we compute CRPS for both training data and test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rUaiDyvPcd1G"
      },
      "outputs": [],
      "source": [
        "from sts.crps import crps_gaussian\n",
        "crps_train = crps_gaussian(y_train.tensor, train_mean, train_var.sqrt())\n",
        "crps_test = crps_gaussian(y_test.tensor, test_mean, test_var.sqrt())\n",
        "print(f'Continuous ranked probability score for training set is: {crps_train.mean().item():.3f}')\n",
        "print(f'Continuous ranked probability score for test set is: {crps_test.mean().item():.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFyuJ3LRcd1G"
      },
      "source": [
        "Here we compute log-likelihood for both training data and test data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pDTx2X8Pcd1G"
      },
      "outputs": [],
      "source": [
        "from sts.metrics import log_likelihood_error\n",
        "ll_train = log_likelihood_error(train_mean, y_train.tensor, train_var).item()\n",
        "ll_test = log_likelihood_error(test_mean, y_test.tensor, test_var).item()\n",
        "print(f'Log-likelihood for training set is: {ll_train:.3f}')\n",
        "print(f'Log-likelihood for test set is: {ll_test:.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Ra79M9G0cd1H"
      },
      "outputs": [],
      "source": [
        "scores = [[MAE_train, crps_train.mean().item(), ll_train], [MAE_test, crps_test.mean().item(), ll_test]]\n",
        "df_meature = pd.DataFrame(scores, columns = ['MAE', 'CPRS', 'LL'])\n",
        "df_meature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQt4PI_Scd1H"
      },
      "source": [
        "\n",
        "The provided table displays the metric values, with the first line representing the training set and the second line representing the test set. It's worth noting that lower values are preferable for MAE and CRPS, while higher values are desired for LL.\n",
        "\n",
        "Upon closer examination, we have observed that the training set exhibits higher accuracy compared to the test set. To address this issue and enhance overall performance, we propose implementing a solution that involves assigning priors to the hyperparameters. Additionally, we will leverage hierarchical priors to capitalize on the joint information present in the univariate time series data.\n",
        "\n",
        "By incorporating these priors into our model, we aim to optimize its performance and reduce the disparity between the accuracy of the training and test sets. This approach will allow us to better capture the underlying patterns and relationships within the data, ultimately improving the model's predictive capabilities."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5ER9tdzHXMU"
      },
      "source": [
        "## **Data Testing - Less Basic**\n",
        "We prepare the training set and test set data and work with using non-standard GPs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wO6Oo0zM9J0O"
      },
      "outputs": [],
      "source": [
        "from sts.gp.model import AdditiveSpectralMixtureTimeSeriesExactGPModel # Check the equivalent models if they have been replaced.\n",
        "from sts.gp.kernel import WhiteNoiseKernel\n",
        "from gpytorch.kernels import LinearKernel, RBFKernel\n",
        "\n",
        "likelihood = gp.likelihoods.GaussianLikelihood()\n",
        "model = AdditiveSpectralMixtureTimeSeriesExactGPModel(df_train, likelihood)\n",
        "model.cov.add_seasonality(\n",
        "            time_axis=\"timestamp\", period_length=365.25, fix_period=True\n",
        "        )\n",
        "model.cov.add_trend(\n",
        "    time_axis=\"timestamp\", kernel_cls=LinearKernel, name=\"LinearTrend\"\n",
        ")\n",
        "model.cov.add_trend(\n",
        "    time_axis=\"timestamp\",\n",
        "    kernel_cls=RBFKernel,\n",
        "    lengthscale=100,\n",
        "    fix_lengthscale=True,\n",
        "    name=\"RBFTrend\",\n",
        ")\n",
        "model.cov.add_spectral_mixture(\n",
        "    time_axis=\"timestamp\",\n",
        "    num_mixtures=2,\n",
        "    train_x=df_train.tensor,\n",
        "    train_y=y_train.tensor,\n",
        "    name=\"SM1\",\n",
        ")\n",
        "model.cov.add_spectral_mixture(\n",
        "    time_axis=\"timestamp\",\n",
        "    num_mixtures=2,\n",
        "    train_x=df_train.tensor,\n",
        "    train_y=y_train.tensor,\n",
        "    name=\"SM2\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7epeUb69J0O"
      },
      "source": [
        "# Training loop\n",
        "We train our model with our training set, and show the training time below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fOTU-3il9J0P"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.01\n",
        "num_epochs = 3000\n",
        "trainer = model.train_init(torch.optim.Adam(model.trainable_params, lr=learning_rate))\n",
        "\n",
        "def train():\n",
        "    for epoch in range(num_epochs):\n",
        "        loss = trainer(df_train, y_train)\n",
        "        if (epoch + 1) % 200 == 1:\n",
        "            print(f'epoch {epoch+1}/{num_epochs}, loss {loss}')\n",
        "\n",
        "%time train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x177LcaU9J0P"
      },
      "source": [
        "# Predictions\n",
        "We use our model to forecast the test set.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VzTZSnsZ9J0P"
      },
      "outputs": [],
      "source": [
        "from sts.data import get_mvn_stats\n",
        "from torch.distributions import ComposeTransform, ExpTransform\n",
        "\n",
        "transform = ComposeTransform([y_train.transforms['log_value'].inv, ExpTransform()])\n",
        "train_mean, train_var, train_ci = get_mvn_stats(model.predict(df_train), transform)\n",
        "test_mean, test_var, test_ci = get_mvn_stats(model.predict(x_test), transform)\n",
        "\n",
        "# This will need to be fixed based on how I created the training and testing datsets.\n",
        "f, ax = plt.subplots(1, 1, figsize=(12, 5))\n",
        "ax.plot(df['timestamp'][:num_trainset], train_mean, alpha=0.8, color='blue', linewidth=1, label='train')\n",
        "ax.plot(df['timestamp'][num_trainset:], test_mean, alpha=0.8, color='green', linewidth=1, label='test')\n",
        "ax.plot(df['timestamp'], df['value'], 'o', markersize=1, color='black', label='actual')\n",
        "ax.fill_between(df['timestamp'], torch.cat([train_ci[0], test_ci[0]]), torch.cat([train_ci[1], test_ci[1]]), alpha=0.2, label='ci', color='gray')\n",
        "ax.legend()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7iKU_dnX9J0Q"
      },
      "source": [
        "The training set has tight credible intervals, while that of the test set is wider. This makes sense since the credible interval gets larger if we extrapolate from the data. But still, we would like to see better performance in the forecasting part.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAgw0CDa9J0Q"
      },
      "source": [
        "# Kernel Decomposition\n",
        "We decompose additive kernels to see how each kernel functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5zZd-ce59J0Q"
      },
      "outputs": [],
      "source": [
        "from sts.gp.graph import plot_components\n",
        "\n",
        "x_all = torch.cat([df_train.tensor, x_test.tensor])\n",
        "components = model.decompose_timeseries(x_all)\n",
        "fig, ax = plot_components(df['timestamp'], components[1], y=model.predict(x_all), transform=transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFSzhwKL9J0Q"
      },
      "source": [
        "# Evaluation\n",
        "We measure mean absolute error (MAE), continuous-ranked probability score (CRPS), and log-likelihood (LL) using normalized values on both of the training set and the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8ZYEp1Sx9J0R"
      },
      "outputs": [],
      "source": [
        "train_mean, train_var, train_ci = get_mvn_stats(model.predict(df_train))\n",
        "test_mean, test_var, test_ci = get_mvn_stats(model.predict(x_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqMVz5Wg9J0R"
      },
      "source": [
        "Here we compute MAE for both training data and test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lK4Eg9EC9J0R"
      },
      "outputs": [],
      "source": [
        "from sts.metrics import MAE\n",
        "MAE_train = MAE(y_train.tensor, train_mean).item()\n",
        "MAE_test = MAE(y_test.tensor, test_mean).item()\n",
        "print(f'Mean absolute error for training set is: {MAE_train:.3f}')\n",
        "print(f'Mean absolute error for test set is: {MAE_test:.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCb939C29J0R"
      },
      "source": [
        "Here we compute CRPS for both training data and test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ODqjYWoV9J0R"
      },
      "outputs": [],
      "source": [
        "from sts.crps import crps_gaussian\n",
        "crps_train = crps_gaussian(y_train.tensor, train_mean, train_var.sqrt())\n",
        "crps_test = crps_gaussian(y_test.tensor, test_mean, test_var.sqrt())\n",
        "print(f'Continuous ranked probability score for training set is: {crps_train.mean().item():.3f}')\n",
        "print(f'Continuous ranked probability score for test set is: {crps_test.mean().item():.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvGiusQr9J0S"
      },
      "source": [
        "Here we compute log-likelihood for both training data and test data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5E3cHOL89J0S"
      },
      "outputs": [],
      "source": [
        "from sts.metrics import log_likelihood_error\n",
        "ll_train = log_likelihood_error(train_mean, y_train.tensor, train_var).item()\n",
        "ll_test = log_likelihood_error(test_mean, y_test.tensor, test_var).item()\n",
        "print(f'Log-likelihood for training set is: {ll_train:.3f}')\n",
        "print(f'Log-likelihood for test set is: {ll_test:.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nChTmCnO9J0S"
      },
      "outputs": [],
      "source": [
        "scores = [[MAE_train, crps_train.mean().item(), ll_train], [MAE_test, crps_test.mean().item(), ll_test]]\n",
        "df_meature = pd.DataFrame(scores, columns = ['MAE', 'CPRS', 'LL'])\n",
        "df_meature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsvtzD349J0S"
      },
      "source": [
        "Above is the table showing the values of each metrics, where the first line is for the training set and the second line is for the test set. As a kind reminder, MAE and CRPS are better if they are lower, while LL is better when it's higher.\n",
        "\n",
        "\n",
        "At the same time, we noticed the training set shows higher accuracy than the test set. To improve this, we will assign priors to the hyperparameters and use the hierarchical priors to gain joint information of univarite time series."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "1Zz-O5859J0S"
      },
      "source": [
        "# References\n",
        "\n",
        "[1] Corani, G., Benavoli, A., Augusto, J. and Zaffalon, M., 2020. Automatic Forecasting using Gaussian Processes. arXiv preprint arXiv:2009.08102."
      ]
    }
  ],
  "metadata": {
    "bento_stylesheets": {
      "bento/extensions/flow/main.css": true,
      "bento/extensions/kernel_selector/main.css": true,
      "bento/extensions/kernel_ui/main.css": true,
      "bento/extensions/new_kernel/main.css": true,
      "bento/extensions/system_usage/main.css": true,
      "bento/extensions/theme/main.css": true
    },
    "captumWidgetMessage": {},
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "outputWidgetContext": {}
  },
  "nbformat": 4,
  "nbformat_minor": 0
}